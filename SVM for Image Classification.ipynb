{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "pleasant-rover",
   "metadata": {},
   "source": [
    "# Using sklearn SVM to classify images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aggressive-pakistan",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, write a function to convert an image to a numpy array\n",
    "\n",
    "# we want a set of features where the first column is a numpy array representing the image\n",
    "# and the second column is the class {fake, real}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "changed-twist",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from os import walk\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "positive-marathon",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'data'\n",
    "real_dir = f'{data_dir}/all_real'\n",
    "fake_dir = f'{data_dir}/all_fake'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "future-bread",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function to process an image\n",
    "\n",
    "def process_image(image):\n",
    "    ''' Scales, crops, and normalizes a PIL image\n",
    "        returns an Numpy array\n",
    "    '''\n",
    "    # resize image so shortest side is 256, maintaining aspect ratio\n",
    "    resize_num = 224\n",
    "    w, h = image.size\n",
    "    (new_w, new_h) = (1 + (resize_num * w // h), resize_num) if w > h else (resize_num, 1 + (resize_num * h // w))\n",
    "    resized = image.resize((new_w, new_h))\n",
    "    \n",
    "    # crop out center 224x224 pixels\n",
    "    resized_w, resized_h = resized.size\n",
    "    w_margin = (resized_w - 224) // 2\n",
    "    h_margin = (resized_h - 224) // 2\n",
    "    (left, upper, right, lower) = (w_margin, h_margin, resized_w - w_margin, resized_h - h_margin)\n",
    "    cropped = resized.crop((left, upper, right, lower))\n",
    "    \n",
    "    # convert values from 0-225 to decimals 0-1\n",
    "    np_image = np.array(cropped)\n",
    "    np_converted = np_image / 255.0\n",
    "    \n",
    "    # normalize via instructions above (hint: look below at provided code in imshow)\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    normalized = (np_converted - mean) / std\n",
    "    \n",
    "    # re-order color channels\n",
    "    reordered = np.transpose(normalized, (2, 0, 1))\n",
    "\n",
    "    return reordered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "controversial-trust",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 225, 224)\n",
      "(151200,)\n"
     ]
    }
   ],
   "source": [
    "# test out the process image function on a single image of a real person\n",
    "\n",
    "bill_murray_image = f'{data_dir}/real_murray.jpg'\n",
    "processed_img = process_image(Image.open(bill_murray_image))\n",
    "print(processed_img.shape)\n",
    "flattened = processed_img.flatten()\n",
    "print(flattened.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "clinical-bottom",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing fake images\n",
      "processing real images\n",
      "[-1.94665639 -1.9809059  -1.92953164 ... -1.17699346 -1.12470588\n",
      "  0.        ]\n",
      "[-1.94665639 -1.9809059  -1.92953164 ... -1.17699346 -1.12470588\n",
      "  1.        ]\n"
     ]
    }
   ],
   "source": [
    "# build an array of arrays to contain X data\n",
    "# [[], [], ... []]\n",
    "# build an array of classes (real, fake) for Y data\n",
    "\n",
    "# run train, test, split twice, making sure that it's randomized, to get train, val, and test\n",
    "\n",
    "fake_image_paths = []\n",
    "for (dirpath, dirnames, filenames) in walk(fake_dir):\n",
    "    fake_image_paths.extend([f'{dirpath}/{fn}' for fn in filenames])\n",
    "# print(fake_image_paths[0:10])\n",
    "\n",
    "real_image_paths = []\n",
    "for (dirpath, dirnames, filenames) in walk(real_dir):\n",
    "    real_image_paths.extend([f'{dirpath}/{fn}' for fn in filenames])\n",
    "# print(real_image_paths[0:10])\n",
    "\n",
    "all_images = []\n",
    "# X = []\n",
    "# y = []\n",
    "print('processing fake images')\n",
    "for fake in fake_image_paths:\n",
    "    all_images.append([*process_image(Image.open(fake)).flatten(), 0])\n",
    "#     y.append(0)\n",
    "    break\n",
    "\n",
    "print('processing real images')\n",
    "for real in real_image_paths:\n",
    "    all_images.append([*process_image(Image.open(fake)).flatten(), 1])\n",
    "#     y.append(1)\n",
    "    break\n",
    "\n",
    "# X = np.array(X)\n",
    "# y = np.array(y)\n",
    "# print(X[0],X[-1])\n",
    "# print(y[0],y[-1])\n",
    "all_images = np.array(all_images)\n",
    "print(all_images[0])\n",
    "print(all_images[-1])\n",
    "\n",
    "# hmm... this is basically 151,200 features per row for less than 600 samples/rows\n",
    "# that doesn't seem good, but we'll try it anyway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "running-jewel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 151201)\n",
      "(2, 151200) (2,)\n",
      "[0. 1.]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# X_train, X__, y_train, y__ = train_test_split(X, y, test_size=0.6, random_state=42)\n",
    "# X_val, X_test, y_val, y_test = train_test_split(X__, y__, test_size=0.5, random_state=42)\n",
    "# print(X_train.shape, X_val.shape, X_test.shape)\n",
    "\n",
    "# shuffle, then just manually take out slices for train, val and test\n",
    "# np.random.shuffle(all_images)\n",
    "# print(all_images[0])\n",
    "# print(all_images[-1])\n",
    "\n",
    "\n",
    "# train is first 400 images\n",
    "train = all_images[0:400, :]\n",
    "X_train, y_train = train[:, 0:-1], train[:, -1]\n",
    "print(X_train.shape, y_train.shape)\n",
    "\n",
    "# val is 401-500\n",
    "val = all_images[400:500, :]\n",
    "X_val, y_val = val[:, 0:-1], val[:, -1]\n",
    "print(X_val.shape, y_val.shape)\n",
    "\n",
    "# test is 501-567\n",
    "test = all_images[500:567, :]\n",
    "X_test, y_test = test[:, 0:-1], test[:, -1]\n",
    "print(X_test.shape, y_test.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
